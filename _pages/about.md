---
layout: about
title: about
permalink: /
subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Motto. Etc.

profile:
  align: right
  image: personal_photo.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>555 your office number</p>
    <p>123 your address street</p>
    <p>Your City, State 12345</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Hi! :wave: I am currently a fourth-year Ph.D. student in the [Department of Computer Science and Engineering](https://www.cse.cuhk.edu.hk/) at [The Chinese University of Hong Kong (CUHK)](https://www.cuhk.edu.hk/), advised by Prof. [Irwin King](https://www.cse.cuhk.edu.hk/people/faculty/irwin-king/) (ACM/IEEE Fellow). Before that, I received my Master's degree from [Sun Yat-sen University (SYSU)](https://www.sysu.edu.cn/), under the supervision of Prof. [Qinliang Su](https://cse.sysu.edu.cn/teacher/SuQinliang). I completed my undergraduate studies at Sun Yat-sen University.

My research interests center around **Large Language Models (LLMs)**. Currently, I focus on **LLM Reasoning and Agentic RL**, aiming to enhance agent exploration capabilities in complex environments (e.g., **DeepResearch Agents**) and balance reasoning efficiency with performance limits (e.g., **Reasoning Compression**, **Test-time Scaling**). I am also interested in the **interplay between LLMs and external knowledge**, investigating robust retrieval mechanisms (e.g., **Entropy-based Decoding for RAG**) and comprehensive assessment benchmarks (e.g., **Long-Context Evaluation**). Previously, my research focused on **Representation Learning**, where I applied methods like Information Bottleneck theory and hyperbolic geometry to improve underlying semantic representations.
